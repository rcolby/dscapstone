{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58ec33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "812217ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"US_youtube_trending_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5977f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = dict()\n",
    "with open('US_category_id.json', 'r') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "for category in category_data['items']:\n",
    "    category_ids[category['id']] = category['snippet']['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40367aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_id_str'] = df['categoryId'].astype('string')\n",
    "df['category_name'] = df['category_id_str'].map(category_ids)\n",
    "df.drop('category_id_str', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f07a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['publishedAt', 'trending_date']] = df[['publishedAt', 'trending_date']].apply(pd.to_datetime)\n",
    "df['days_to_trend'] = (df['trending_date'] - df['publishedAt']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ced9f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['video_id', 'title', 'channelId', 'channelTitle', 'categoryId', 'category_name',\n",
    "        'publishedAt', 'trending_date', 'days_to_trend','comment_count', 'view_count', 'likes', 'dislikes', \n",
    "        'comments_disabled', 'thumbnail_link', 'ratings_disabled', 'description', 'tags'])\n",
    "df.drop('thumbnail_link', axis=1, inplace=True)\n",
    "df.rename(columns = {'channelId':'channel_id', 'channelTitle':'channel_title', 'publishedAt': 'published_at',\n",
    "                     'categoryId': 'category_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b52acecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count - unique description sentiments:\t1\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = analyzer.polarity_scores(text)\n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_dict['compound'] <= - 0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "df = df.assign(desc_sentiment = lambda x: get_sentiment(x))\n",
    "\n",
    "print('Count - unique description sentiments:\\t{count}'.format(count=len(pd.unique(df['desc_sentiment']))))\n",
    "\n",
    "df.drop('desc_sentiment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "474d94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.sort_values(by = 'trending_date', ascending=False, inplace=True)\n",
    "df2.reset_index(inplace=True)\n",
    "df2.drop(df2[df2['comments_disabled'] == True].index, inplace = True)\n",
    "n = len(df2.axes[0]) - 120\n",
    "df2.drop(df2.tail(n).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649aa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_comments_to_json(video_id):\n",
    "    result = {'video_id': video_id}\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.youtube.com/watch?v={id}'.format(id=video_id))\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'description')))\n",
    "\n",
    "    html = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'html')))\n",
    "    html.send_keys(Keys.PAGE_DOWN)\n",
    "    html.send_keys(Keys.PAGE_DOWN)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'contents')))\n",
    "    for i in range(10):\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    comment_elems = driver.find_elements(By.XPATH, '//*[@id=\"content-text\"]')\n",
    "    \n",
    "    comments = [elem.text for elem in comment_elems][0:100]\n",
    "    if len(comments) < 100:\n",
    "        pass\n",
    "    else:\n",
    "        result['comments'] = comments\n",
    "        with open(\"comments/{filename}.json\".format(filename=video_id), 'w') as f:\n",
    "            json.dump(result, f)\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "video_ids = df2[\"video_id\"].to_list()\n",
    "\n",
    "for video_id in video_ids:\n",
    "    write_comments_to_json(video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5010d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "directory = 'comments'\n",
    " \n",
    "for filename in os.listdir(directory):\n",
    "    fp = os.path.join(directory, filename)\n",
    "    if os.path.isfile(fp) and fp.endswith('.json'):\n",
    "        with open(fp, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            result = {'video_id': data['video_id'], 'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "            for comment in data[\"comments\"]:\n",
    "                sentiment_dict = analyzer.polarity_scores(comment)\n",
    "                if sentiment_dict['compound'] >= 0.05:\n",
    "                    result['positive'] += 1\n",
    "                elif sentiment_dict['compound'] <= - 0.05:\n",
    "                    result['negative'] += 1\n",
    "                else:\n",
    "                    result['neutral'] += 1\n",
    "            results.append(result)\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf946df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df2,  on='video_id', how='left')\n",
    "df4 = df4.drop(columns=['index'])\n",
    "df4.to_csv('output/ytsentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67619600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
